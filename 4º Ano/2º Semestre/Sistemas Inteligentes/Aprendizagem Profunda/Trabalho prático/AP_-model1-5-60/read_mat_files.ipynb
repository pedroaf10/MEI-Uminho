{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "train_mat = scipy.io.loadmat('train_data.mat') \n",
    "test_mat = scipy.io.loadmat('test_data.mat') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'train_data'])\n",
      "dict_keys(['__header__', '__version__', '__globals__', 'test_data'])\n",
      "(112, 90, 90)\n",
      "(28, 90, 90)\n"
     ]
    }
   ],
   "source": [
    "def get_data_from_mat(train_file,test_file):\n",
    "    train_mat = scipy.io.loadmat(train_file) \n",
    "    test_mat = scipy.io.loadmat(test_file) \n",
    "    print(train_mat.keys())\n",
    "    print(test_mat.keys())\n",
    "    train_np = np.array(train_mat['train_data']).transpose(2,0,1)\n",
    "    test_np = np.array(test_mat['test_data']).transpose(2,0,1)\n",
    "    print(train_np.shape)\n",
    "    print(test_np.shape)\n",
    "    return  train_np, test_np\n",
    "\n",
    "\n",
    "train_data, test_data = get_data_from_mat('train_data.mat','test_data.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.13152513 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.13152513 0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.28060623]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.28060623 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds shape: (112, 90, 90)\n",
      "ds max: 1.0\n",
      "ds min: 0.0\n",
      "ds average: 0.024116160549305543\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d972585cb9c460b9dd99e9c176794cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=55, description='scan_index', max=111), Output()), _dom_classes=('widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, interact\n",
    "\n",
    "def visualize(image):  \n",
    "    #plt.figure(\"sample\", (12, 6))\n",
    "    #plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image, cmap=\"gray\")    \n",
    "    #plt.subplot(1, 2, 2)\n",
    "    #plt.imshow(image, cmap=\"gray\")\n",
    "    plt.show()      \n",
    "\n",
    "\n",
    "#@interact\n",
    "def show_ds(ds):\n",
    "    print(\"ds shape:\",ds.shape)\n",
    "    print(\"ds max:\",np.max(ds))\n",
    "    print(\"ds min:\",np.min(ds))\n",
    "    print(\"ds average:\",np.average(ds))\n",
    "    @interact\n",
    "    def visualize_set(scan_index=(0,len(ds)-1)):\n",
    "        #print(scan_index)\n",
    "        visualize(ds[scan_index,:,:])\n",
    "\n",
    "show_ds(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds shape: (28, 90, 90)\n",
      "ds max: 1.0\n",
      "ds min: 0.0\n",
      "ds average: 0.024994026906171023\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369f514475c64704aea7d85d76663f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=13, description='scan_index', max=27), Output()), _dom_classes=('widget-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_ds(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__header__</td>\n",
       "      <td>b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__version__</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__globals__</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_data</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                               list\n",
       "0   __header__  b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Crea...\n",
       "1  __version__                                                1.0\n",
       "2  __globals__                                                 []\n",
       "3   train_data  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0..."
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat('train_data.mat')\n",
    "pqr=pd.Series(mat)\n",
    "pd.DataFrame({'label':pqr.index, 'list':pqr.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__header__     b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Crea...\n",
      "__version__                                                  1.0\n",
      "__globals__                                                   []\n",
      "train_data     [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(pqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt(\"train.csv\", delimiter=\",\")\n",
    "data = data[1:]\n",
    "X = np.delete(data, 1, 1)\n",
    "X = np.delete(X, 0, 1)\n",
    "\n",
    "Y = np.delete(data, 0, 1)\n",
    "Y = np.delete(Y, 2, 1)\n",
    "Y = np.delete(Y, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X: (112, 2)\n",
      "Shape Y: (112, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape X: {X.shape}\")\n",
    "print(f\"Shape Y: {Y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(2)\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_random_seeds():\n",
    "   os.environ['PYTHONHASHSEED']=str(2)\n",
    "   tf.random.set_seed(2)\n",
    "   np.random.seed(2)\n",
    "   random.seed(2)\n",
    "\n",
    "reset_random_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 90, 90)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.reshape(train_data.shape[0],90,90,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 90, 90, 1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 88, 88, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 88, 88, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 44, 44, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 42, 42, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 19, 19, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                663616    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 756,481\n",
      "Trainable params: 756,417\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reset_random_seeds()\n",
    "model = tf.keras.Sequential([\n",
    "    L.InputLayer(input_shape=(90,90,1)),\n",
    "    L.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPooling2D((2, 2)),\n",
    "    L.Conv2D(64, (3, 3), activation='relu'),\n",
    "    L.MaxPooling2D((2, 2)),\n",
    "    L.Conv2D(128, (3, 3), activation='relu'),\n",
    "    L.MaxPooling2D((2, 2)),\n",
    "    L.Flatten(),\n",
    "    L.Dense(64, activation='relu'),\n",
    "    L.Dropout(rate=0.5),\n",
    "    L.Dense(1, activation='relu')\n",
    "])\n",
    "\n",
    "sgd = tf.keras.optimizers.SGD(momentum=0.9)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])\n",
    "\n",
    "\n",
    "## Stop training when validation loss reach 110\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('val_loss')<110):\n",
    "            print(\"\\nReached 110 val_loss so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "        \n",
    "callback = myCallback()\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 1565.5743 - mae: 33.7804 - val_loss: 4162.2544 - val_mae: 63.9758\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 910.9269 - mae: 24.5266 - val_loss: 4323.3647 - val_mae: 65.2231\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 558.0158 - mae: 20.8642 - val_loss: 4394.9644 - val_mae: 65.7698\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 683.1244 - mae: 20.8372 - val_loss: 4362.4731 - val_mae: 65.5223\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 546.5639 - mae: 20.3331 - val_loss: 4279.2495 - val_mae: 64.8840\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 530.3432 - mae: 19.6990 - val_loss: 4254.9497 - val_mae: 64.6965\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 589.5125 - mae: 20.6452 - val_loss: 4314.7446 - val_mae: 65.1571\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 529.1562 - mae: 19.5262 - val_loss: 4359.0747 - val_mae: 65.4965\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 539.8510 - mae: 19.4809 - val_loss: 4344.5659 - val_mae: 65.3856\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 520.3034 - mae: 18.9699 - val_loss: 4286.3867 - val_mae: 64.9391\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 478.4223 - mae: 19.1133 - val_loss: 4253.7012 - val_mae: 64.6869\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 480.7196 - mae: 18.5612 - val_loss: 4293.7866 - val_mae: 64.9961\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 397.6352 - mae: 17.2501 - val_loss: 4319.2266 - val_mae: 65.1915\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 471.6652 - mae: 18.2698 - val_loss: 4313.2036 - val_mae: 65.1453\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 442.1582 - mae: 18.2744 - val_loss: 4273.8325 - val_mae: 64.8423\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 485.6140 - mae: 19.0714 - val_loss: 4252.9888 - val_mae: 64.6814\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 387.1511 - mae: 17.3108 - val_loss: 4268.9395 - val_mae: 64.8046\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 397.2473 - mae: 16.8155 - val_loss: 4291.2671 - val_mae: 64.9766\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 425.9603 - mae: 17.4536 - val_loss: 4277.7344 - val_mae: 64.8723\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 373.2095 - mae: 16.1374 - val_loss: 4232.9243 - val_mae: 64.5259\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 386.7834 - mae: 17.0274 - val_loss: 4227.6753 - val_mae: 64.4851\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 367.6677 - mae: 15.9871 - val_loss: 4263.0889 - val_mae: 64.7591\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 335.3746 - mae: 15.2669 - val_loss: 4225.7134 - val_mae: 64.4697\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 293.4667 - mae: 14.3552 - val_loss: 4223.4214 - val_mae: 64.4518\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 323.2246 - mae: 15.2197 - val_loss: 4236.9360 - val_mae: 64.5565\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 374.1174 - mae: 15.9715 - val_loss: 4202.2378 - val_mae: 64.2869\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 268.6539 - mae: 14.0185 - val_loss: 4159.2271 - val_mae: 63.9512\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 300.6677 - mae: 14.3343 - val_loss: 4195.5571 - val_mae: 64.2345\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 273.3085 - mae: 13.7242 - val_loss: 4193.8735 - val_mae: 64.2211\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 283.0411 - mae: 14.2413 - val_loss: 4139.6128 - val_mae: 63.7969\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 261.9113 - mae: 12.9278 - val_loss: 4169.1987 - val_mae: 64.0281\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 273.6561 - mae: 13.0229 - val_loss: 4146.2485 - val_mae: 63.8484\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 251.0964 - mae: 12.6359 - val_loss: 4097.1001 - val_mae: 63.4620\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 230.0190 - mae: 12.1284 - val_loss: 4106.5898 - val_mae: 63.5365\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 297.0359 - mae: 13.8325 - val_loss: 4109.4585 - val_mae: 63.5590\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 245.1125 - mae: 12.5292 - val_loss: 4044.1914 - val_mae: 63.0435\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 217.3848 - mae: 12.1044 - val_loss: 4058.0410 - val_mae: 63.1531\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 212.0145 - mae: 11.3271 - val_loss: 4011.6145 - val_mae: 62.7846\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 187.1171 - mae: 10.5785 - val_loss: 3935.4597 - val_mae: 62.1754\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 193.4955 - mae: 10.8229 - val_loss: 4080.4453 - val_mae: 63.3309\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 298.0194 - mae: 12.6967 - val_loss: 3931.2981 - val_mae: 62.1425\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 240.4753 - mae: 11.9561 - val_loss: 3897.9570 - val_mae: 61.8741\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 179.6898 - mae: 11.1408 - val_loss: 4039.7773 - val_mae: 63.0102\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 319.7987 - mae: 13.6449 - val_loss: 3936.1104 - val_mae: 62.1825\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 161.5643 - mae: 10.3066 - val_loss: 3846.7998 - val_mae: 61.4603\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 278.0243 - mae: 13.5658 - val_loss: 4010.9861 - val_mae: 62.7823\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 260.5762 - mae: 12.3985 - val_loss: 3979.3281 - val_mae: 62.5299\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 218.3665 - mae: 11.4273 - val_loss: 3849.3557 - val_mae: 61.4820\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 221.3633 - mae: 11.8441 - val_loss: 3972.1487 - val_mae: 62.4730\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 197.5132 - mae: 10.9582 - val_loss: 3972.4949 - val_mae: 62.4761\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 214.0379 - mae: 11.6891 - val_loss: 3862.2981 - val_mae: 61.5882\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 160.9610 - mae: 10.1514 - val_loss: 3857.6189 - val_mae: 61.5504\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 212.9733 - mae: 11.7218 - val_loss: 3961.1833 - val_mae: 62.3863\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 180.1798 - mae: 10.4091 - val_loss: 3943.3320 - val_mae: 62.2432\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 208.6268 - mae: 11.1059 - val_loss: 3860.7551 - val_mae: 61.5765\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 226.0175 - mae: 12.3032 - val_loss: 3874.0039 - val_mae: 61.6841\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 209.5710 - mae: 11.5381 - val_loss: 3926.4163 - val_mae: 62.1076\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 197.6385 - mae: 10.4846 - val_loss: 3826.5500 - val_mae: 61.2986\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 224.3711 - mae: 11.9859 - val_loss: 3846.3115 - val_mae: 61.4598\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 49ms/step - loss: 180.8288 - mae: 10.6719 - val_loss: 3878.3728 - val_mae: 61.7203\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 175.2529 - mae: 10.1239 - val_loss: 3818.7141 - val_mae: 61.2356\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 156.8721 - mae: 9.7612 - val_loss: 3824.6101 - val_mae: 61.2840\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 148.1518 - mae: 9.8513 - val_loss: 3851.2109 - val_mae: 61.5009\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 141.5205 - mae: 9.2078 - val_loss: 3838.4258 - val_mae: 61.3973\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 151.6012 - mae: 9.5439 - val_loss: 3812.2668 - val_mae: 61.1845\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 162.8473 - mae: 9.8775 - val_loss: 3799.2539 - val_mae: 61.0786\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 103.4243 - mae: 7.8570 - val_loss: 3785.7878 - val_mae: 60.9688\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 130.3339 - mae: 9.0974 - val_loss: 3790.1934 - val_mae: 61.0055\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 104.4450 - mae: 8.1062 - val_loss: 3814.8972 - val_mae: 61.2080\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 140.4283 - mae: 9.2799 - val_loss: 3768.2637 - val_mae: 60.8263\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 130.7095 - mae: 8.9370 - val_loss: 3817.5349 - val_mae: 61.2302\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 139.6736 - mae: 8.9738 - val_loss: 3768.9119 - val_mae: 60.8324\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 133.1315 - mae: 8.6590 - val_loss: 3735.7092 - val_mae: 60.5592\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 134.6573 - mae: 9.3144 - val_loss: 3781.4180 - val_mae: 60.9357\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 143.4884 - mae: 9.1086 - val_loss: 3773.2312 - val_mae: 60.8688\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 98.3481 - mae: 7.6545 - val_loss: 3742.2920 - val_mae: 60.6145\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 111.2347 - mae: 8.3166 - val_loss: 3704.6052 - val_mae: 60.3033\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 126.1769 - mae: 8.5017 - val_loss: 3758.7976 - val_mae: 60.7511\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 143.0916 - mae: 9.3014 - val_loss: 3785.6443 - val_mae: 60.9718\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 142.3540 - mae: 9.1849 - val_loss: 3720.5891 - val_mae: 60.4364\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 118.4060 - mae: 8.7902 - val_loss: 3721.9514 - val_mae: 60.4482\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 151.2484 - mae: 9.2130 - val_loss: 3809.7249 - val_mae: 61.1701\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 148.2290 - mae: 9.2322 - val_loss: 3748.9192 - val_mae: 60.6719\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 110.8185 - mae: 8.3231 - val_loss: 3667.5867 - val_mae: 59.9985\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 167.7559 - mae: 9.7373 - val_loss: 3719.3254 - val_mae: 60.4284\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 174.0961 - mae: 9.9559 - val_loss: 3773.5564 - val_mae: 60.8757\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 153.6160 - mae: 9.6364 - val_loss: 3658.0195 - val_mae: 59.9197\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 107.6952 - mae: 8.2822 - val_loss: 3647.8640 - val_mae: 59.8349\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 90.7985 - mae: 7.4727 - val_loss: 3754.0486 - val_mae: 60.7156\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 124.8608 - mae: 8.7759 - val_loss: 3669.7507 - val_mae: 60.0176\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 136.1265 - mae: 8.8862 - val_loss: 3609.2786 - val_mae: 59.5118\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 168.3475 - mae: 10.0635 - val_loss: 3705.8054 - val_mae: 60.3171\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 152.6975 - mae: 9.3007 - val_loss: 3685.8301 - val_mae: 60.1512\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 133.9692 - mae: 8.8170 - val_loss: 3611.1160 - val_mae: 59.5271\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 151.7515 - mae: 9.6954 - val_loss: 3671.8428 - val_mae: 60.0354\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 128.9737 - mae: 8.0992 - val_loss: 3692.9785 - val_mae: 60.2117\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 109.9244 - mae: 7.5319 - val_loss: 3637.3875 - val_mae: 59.7492\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 100.7809 - mae: 7.7598 - val_loss: 3621.1670 - val_mae: 59.6143\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 105.6520 - mae: 7.9082 - val_loss: 3617.0872 - val_mae: 59.5807\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 114.9542 - mae: 8.0263 - val_loss: 3639.3848 - val_mae: 59.7680\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 137.0463 - mae: 8.8120 - val_loss: 3609.4329 - val_mae: 59.5174\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 156.5347 - mae: 9.3497 - val_loss: 3638.1931 - val_mae: 59.7589\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 133.9941 - mae: 9.0194 - val_loss: 3682.8328 - val_mae: 60.1311\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 95.3339 - mae: 7.7328 - val_loss: 3569.7219 - val_mae: 59.1839\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 114.3732 - mae: 8.1841 - val_loss: 3597.7034 - val_mae: 59.4199\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 112.7829 - mae: 8.1436 - val_loss: 3689.0979 - val_mae: 60.1839\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 130.4161 - mae: 8.8527 - val_loss: 3597.3728 - val_mae: 59.4177\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 113.0876 - mae: 8.0833 - val_loss: 3476.9023 - val_mae: 58.3955\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 153.3608 - mae: 9.3269 - val_loss: 3666.4531 - val_mae: 59.9959\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 186.6779 - mae: 10.6260 - val_loss: 3659.6907 - val_mae: 59.9403\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 143.2977 - mae: 9.3134 - val_loss: 3501.3828 - val_mae: 58.6064\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 107.4797 - mae: 8.3631 - val_loss: 3562.2383 - val_mae: 59.1228\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 112.2582 - mae: 7.7979 - val_loss: 3637.1523 - val_mae: 59.7523\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 164.2342 - mae: 9.5515 - val_loss: 3549.2461 - val_mae: 59.0121\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 96.6640 - mae: 7.5872 - val_loss: 3421.9202 - val_mae: 57.9232\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 139.7796 - mae: 9.2079 - val_loss: 3530.9033 - val_mae: 58.8557\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 115.8460 - mae: 8.3654 - val_loss: 3622.6687 - val_mae: 59.6299\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 144.5466 - mae: 9.2387 - val_loss: 3460.4734 - val_mae: 58.2546\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 138.8083 - mae: 8.8345 - val_loss: 3422.3372 - val_mae: 57.9266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 112.9201 - mae: 8.3821 - val_loss: 3614.5901 - val_mae: 59.5623\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 138.7833 - mae: 9.1353 - val_loss: 3622.6846 - val_mae: 59.6303\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 138.8939 - mae: 8.8944 - val_loss: 3401.5342 - val_mae: 57.7478\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 144.0695 - mae: 9.7443 - val_loss: 3414.5403 - val_mae: 57.8600\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 92.6952 - mae: 8.0596 - val_loss: 3591.7522 - val_mae: 59.3718\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 146.0538 - mae: 9.2645 - val_loss: 3599.2539 - val_mae: 59.4359\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 161.9571 - mae: 9.6525 - val_loss: 3344.7000 - val_mae: 57.2566\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 139.8418 - mae: 9.6059 - val_loss: 3333.3801 - val_mae: 57.1581\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 125.7204 - mae: 8.7870 - val_loss: 3535.3262 - val_mae: 58.8974\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 163.6405 - mae: 9.9786 - val_loss: 3504.0735 - val_mae: 58.6322\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 122.7128 - mae: 8.3432 - val_loss: 3291.0476 - val_mae: 56.7878\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 150.0932 - mae: 9.5362 - val_loss: 3316.0859 - val_mae: 57.0080\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 97.5691 - mae: 7.7078 - val_loss: 3545.6619 - val_mae: 58.9866\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 192.6841 - mae: 11.0220 - val_loss: 3525.5039 - val_mae: 58.8156\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 102.9485 - mae: 7.3572 - val_loss: 3299.2322 - val_mae: 56.8603\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 126.8464 - mae: 8.8922 - val_loss: 3283.2256 - val_mae: 56.7193\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 121.1257 - mae: 8.4500 - val_loss: 3453.6416 - val_mae: 58.2013\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 142.2036 - mae: 8.6316 - val_loss: 3520.1172 - val_mae: 58.7691\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 151.7684 - mae: 9.5066 - val_loss: 3378.0525 - val_mae: 57.5488\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 133.9282 - mae: 8.7144 - val_loss: 3251.8147 - val_mae: 56.4426\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 112.5670 - mae: 8.5295 - val_loss: 3334.4407 - val_mae: 57.1709\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 123.1099 - mae: 8.3172 - val_loss: 3462.4277 - val_mae: 58.2800\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 114.4360 - mae: 8.2995 - val_loss: 3401.2795 - val_mae: 57.7537\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 116.9476 - mae: 7.9171 - val_loss: 3231.6946 - val_mae: 56.2669\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 106.3515 - mae: 7.9707 - val_loss: 3205.1895 - val_mae: 56.0311\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 120.3472 - mae: 8.4244 - val_loss: 3393.8367 - val_mae: 57.6898\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 126.5864 - mae: 8.4264 - val_loss: 3360.6467 - val_mae: 57.4015\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 120.0623 - mae: 7.8746 - val_loss: 3172.7874 - val_mae: 55.7411\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 141.3412 - mae: 9.2677 - val_loss: 3188.4131 - val_mae: 55.8800\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 70.8816 - mae: 6.5340 - val_loss: 3278.9236 - val_mae: 56.6828\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 105.7133 - mae: 7.2025 - val_loss: 3287.2698 - val_mae: 56.7557\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 86.4532 - mae: 7.0806 - val_loss: 3239.8303 - val_mae: 56.3356\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 68.6033 - mae: 6.7299 - val_loss: 3237.6387 - val_mae: 56.3155\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 106.9721 - mae: 7.7315 - val_loss: 3171.0615 - val_mae: 55.7216\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 75.2806 - mae: 6.4845 - val_loss: 3123.4573 - val_mae: 55.2933\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 68.5861 - mae: 6.3861 - val_loss: 3121.2305 - val_mae: 55.2726\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 92.6070 - mae: 7.4830 - val_loss: 3219.8391 - val_mae: 56.1572\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 83.0684 - mae: 6.9783 - val_loss: 3223.9961 - val_mae: 56.1947\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 94.0966 - mae: 7.7494 - val_loss: 3104.3743 - val_mae: 55.1215\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 106.1646 - mae: 8.0069 - val_loss: 3042.0232 - val_mae: 54.5543\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 103.6287 - mae: 7.9489 - val_loss: 3166.6414 - val_mae: 55.6850\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 107.6997 - mae: 7.6306 - val_loss: 3188.7861 - val_mae: 55.8829\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 92.8242 - mae: 7.0071 - val_loss: 3034.7834 - val_mae: 54.4868\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 103.5373 - mae: 7.4969 - val_loss: 3017.2610 - val_mae: 54.3250\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 82.6594 - mae: 6.7526 - val_loss: 3140.4863 - val_mae: 55.4467\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 96.8688 - mae: 7.4535 - val_loss: 3067.9346 - val_mae: 54.7890\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 91.3260 - mae: 7.4561 - val_loss: 2958.4153 - val_mae: 53.7815\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 118.5696 - mae: 7.9334 - val_loss: 2983.6836 - val_mae: 54.0169\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 110.4696 - mae: 8.2031 - val_loss: 3072.1917 - val_mae: 54.8301\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 101.1400 - mae: 7.2346 - val_loss: 3015.8958 - val_mae: 54.3160\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 101.4458 - mae: 7.4396 - val_loss: 2969.4978 - val_mae: 53.8909\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 85.3650 - mae: 7.0011 - val_loss: 2915.8699 - val_mae: 53.3935\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 110.7573 - mae: 8.2855 - val_loss: 2923.0247 - val_mae: 53.4605\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 87.9864 - mae: 7.0031 - val_loss: 2977.8464 - val_mae: 53.9698\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 99.5404 - mae: 7.7638 - val_loss: 2978.7676 - val_mae: 53.9783\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 96.7050 - mae: 7.6768 - val_loss: 2922.0479 - val_mae: 53.4502\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 86.3717 - mae: 7.3911 - val_loss: 2891.1179 - val_mae: 53.1589\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 73.2524 - mae: 6.6138 - val_loss: 2900.6360 - val_mae: 53.2477\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 117.9994 - mae: 7.9778 - val_loss: 2869.4053 - val_mae: 52.9519\n",
      "Epoch 179/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 60ms/step - loss: 127.0713 - mae: 8.7323 - val_loss: 2784.6660 - val_mae: 52.1439\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 92.9425 - mae: 6.9395 - val_loss: 2816.6162 - val_mae: 52.4480\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 93.3382 - mae: 7.3633 - val_loss: 2846.0417 - val_mae: 52.7278\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 83.4409 - mae: 6.7990 - val_loss: 2707.6035 - val_mae: 51.3991\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 77.1223 - mae: 6.7210 - val_loss: 2756.7415 - val_mae: 51.8768\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 130.7112 - mae: 8.5250 - val_loss: 2841.5959 - val_mae: 52.6917\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 78.2770 - mae: 6.5687 - val_loss: 2766.3262 - val_mae: 51.9746\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 98.4915 - mae: 7.6841 - val_loss: 2753.7874 - val_mae: 51.8544\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 95.0184 - mae: 7.2438 - val_loss: 2810.5071 - val_mae: 52.3976\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 90.8366 - mae: 6.6883 - val_loss: 2788.6038 - val_mae: 52.1863\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 90.6212 - mae: 7.2846 - val_loss: 2664.6113 - val_mae: 50.9834\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 97.1481 - mae: 7.3214 - val_loss: 2762.0300 - val_mae: 51.9282\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 89.4601 - mae: 7.0978 - val_loss: 2727.7185 - val_mae: 51.5960\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 107.5340 - mae: 7.2300 - val_loss: 2593.9785 - val_mae: 50.2816\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 145.4113 - mae: 8.8915 - val_loss: 2648.7859 - val_mae: 50.8225\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 84.8646 - mae: 7.3948 - val_loss: 2704.4031 - val_mae: 51.3655\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 90.8079 - mae: 6.8210 - val_loss: 2566.3540 - val_mae: 50.0035\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 78.9483 - mae: 6.8587 - val_loss: 2486.1365 - val_mae: 49.1925\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 96.7640 - mae: 7.3325 - val_loss: 2499.3579 - val_mae: 49.3232\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 132.8483 - mae: 8.5699 - val_loss: 2600.4658 - val_mae: 50.3365\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 99.7509 - mae: 7.3642 - val_loss: 2677.3833 - val_mae: 51.0955\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 109.1655 - mae: 7.8301 - val_loss: 2513.2754 - val_mae: 49.4651\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 85.7303 - mae: 6.3484 - val_loss: 2467.4021 - val_mae: 49.0012\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 110.8174 - mae: 7.7722 - val_loss: 2547.9253 - val_mae: 49.8173\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 100.7796 - mae: 7.2679 - val_loss: 2491.6667 - val_mae: 49.2476\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 77.7833 - mae: 6.6179 - val_loss: 2499.8738 - val_mae: 49.3297\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 76.9715 - mae: 6.4473 - val_loss: 2459.9656 - val_mae: 48.9222\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 80.1818 - mae: 6.9108 - val_loss: 2354.7969 - val_mae: 47.8335\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 69.1944 - mae: 6.2062 - val_loss: 2393.8203 - val_mae: 48.2398\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 110.0993 - mae: 7.6791 - val_loss: 2490.5698 - val_mae: 49.2350\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 84.1015 - mae: 7.1938 - val_loss: 2409.2747 - val_mae: 48.4034\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 82.1230 - mae: 6.5168 - val_loss: 2285.2969 - val_mae: 47.1055\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 98.4563 - mae: 6.9981 - val_loss: 2312.4553 - val_mae: 47.3924\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 86.0594 - mae: 7.0700 - val_loss: 2388.4856 - val_mae: 48.1862\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 79.3904 - mae: 6.7028 - val_loss: 2388.6003 - val_mae: 48.1851\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 92.7400 - mae: 6.8949 - val_loss: 2402.3103 - val_mae: 48.3252\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 95.9782 - mae: 7.1108 - val_loss: 2266.8936 - val_mae: 46.9008\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 80.8683 - mae: 6.9828 - val_loss: 2311.6416 - val_mae: 47.3790\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 100.3984 - mae: 7.7357 - val_loss: 2235.3840 - val_mae: 46.5687\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 84.8616 - mae: 6.8656 - val_loss: 2290.5244 - val_mae: 47.1562\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 86.3661 - mae: 7.0076 - val_loss: 2352.1406 - val_mae: 47.8047\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 125.7501 - mae: 8.3918 - val_loss: 2245.2559 - val_mae: 46.6741\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 73.4583 - mae: 6.1366 - val_loss: 2080.8953 - val_mae: 44.8794\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 73.6716 - mae: 6.7853 - val_loss: 2228.0486 - val_mae: 46.4879\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 82.2662 - mae: 6.4747 - val_loss: 2260.0967 - val_mae: 46.8282\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 84.4545 - mae: 6.9941 - val_loss: 2116.6272 - val_mae: 45.2645\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 81.8705 - mae: 6.9401 - val_loss: 2110.4609 - val_mae: 45.1903\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 99.3512 - mae: 8.0182 - val_loss: 2215.6936 - val_mae: 46.3361\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 90.0770 - mae: 7.1300 - val_loss: 2071.5330 - val_mae: 44.7497\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 108.3089 - mae: 7.3324 - val_loss: 1945.0938 - val_mae: 43.3113\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 95.0338 - mae: 7.5292 - val_loss: 2026.0824 - val_mae: 44.2374\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 73.3840 - mae: 6.4399 - val_loss: 2103.9988 - val_mae: 45.1106\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 60.9125 - mae: 6.2607 - val_loss: 2009.8334 - val_mae: 44.0527\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 70.3133 - mae: 6.5724 - val_loss: 1877.8414 - val_mae: 42.5241\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 84.5223 - mae: 6.9085 - val_loss: 2082.3269 - val_mae: 44.8655\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 89.9978 - mae: 7.2769 - val_loss: 2022.2548 - val_mae: 44.1880\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 80.2092 - mae: 6.4290 - val_loss: 1849.9258 - val_mae: 42.1876\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 90.5195 - mae: 6.9380 - val_loss: 1940.1602 - val_mae: 43.2441\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 70.3172 - mae: 5.9893 - val_loss: 2041.0596 - val_mae: 44.3958\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 87.8633 - mae: 6.7207 - val_loss: 1997.1598 - val_mae: 43.8949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 97.9303 - mae: 7.5965 - val_loss: 1874.9801 - val_mae: 42.4774\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 88.0333 - mae: 6.9907 - val_loss: 1820.1813 - val_mae: 41.8267\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 93.1370 - mae: 6.9945 - val_loss: 2026.0482 - val_mae: 44.2256\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 110.6626 - mae: 7.2935 - val_loss: 1929.0249 - val_mae: 43.1169\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 62.7149 - mae: 6.1615 - val_loss: 1631.6549 - val_mae: 39.5217\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 130.9126 - mae: 8.7655 - val_loss: 1857.3666 - val_mae: 42.2869\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 116.8148 - mae: 7.6926 - val_loss: 1982.1279 - val_mae: 43.7405\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 113.7231 - mae: 8.3217 - val_loss: 1689.5049 - val_mae: 40.2556\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 96.4969 - mae: 7.3930 - val_loss: 1535.8212 - val_mae: 38.2907\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 92.4986 - mae: 7.1085 - val_loss: 1805.9471 - val_mae: 41.6635\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 101.8101 - mae: 7.7808 - val_loss: 1959.4418 - val_mae: 43.4612\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 98.4610 - mae: 7.5279 - val_loss: 1699.0181 - val_mae: 40.3481\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 84.6488 - mae: 6.8582 - val_loss: 1511.0433 - val_mae: 37.9381\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 103.1843 - mae: 7.7584 - val_loss: 1756.5371 - val_mae: 41.0445\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 98.3326 - mae: 7.2943 - val_loss: 1881.5430 - val_mae: 42.5410\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 92.5172 - mae: 7.4032 - val_loss: 1645.1123 - val_mae: 39.6652\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 115.8621 - mae: 7.5621 - val_loss: 1528.4413 - val_mae: 38.1715\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 96.7374 - mae: 7.5846 - val_loss: 1725.0059 - val_mae: 40.6762\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 106.0359 - mae: 7.5362 - val_loss: 1740.0836 - val_mae: 40.8710\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 100.1548 - mae: 7.5806 - val_loss: 1459.0280 - val_mae: 37.2745\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 111.1480 - mae: 7.9935 - val_loss: 1426.7379 - val_mae: 36.8416\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 121.1276 - mae: 8.5903 - val_loss: 1691.4930 - val_mae: 40.2817\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 110.3903 - mae: 7.9089 - val_loss: 1545.4850 - val_mae: 38.4163\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 77.7198 - mae: 6.3251 - val_loss: 1366.8740 - val_mae: 35.9962\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 82.0285 - mae: 6.9412 - val_loss: 1543.8707 - val_mae: 38.3676\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 108.4953 - mae: 7.5918 - val_loss: 1564.6812 - val_mae: 38.6301\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 75.5663 - mae: 6.4326 - val_loss: 1331.7910 - val_mae: 35.4792\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 98.0057 - mae: 7.2363 - val_loss: 1252.0049 - val_mae: 34.3322\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 110.5849 - mae: 7.6812 - val_loss: 1548.8873 - val_mae: 38.4223\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 83.1438 - mae: 6.5576 - val_loss: 1491.2135 - val_mae: 37.6596\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 84.8528 - mae: 6.6517 - val_loss: 1349.7836 - val_mae: 35.7262\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 87.0735 - mae: 6.8563 - val_loss: 1344.9469 - val_mae: 35.6595\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 95.4956 - mae: 7.4813 - val_loss: 1344.4474 - val_mae: 35.6474\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 67.7103 - mae: 6.1167 - val_loss: 1335.2538 - val_mae: 35.4976\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 87.7533 - mae: 6.8744 - val_loss: 1330.5780 - val_mae: 35.4069\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 88.7203 - mae: 6.3137 - val_loss: 1177.0332 - val_mae: 33.1350\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 97.3635 - mae: 6.9990 - val_loss: 1261.2987 - val_mae: 34.3660\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 78.0790 - mae: 6.4813 - val_loss: 1399.2574 - val_mae: 36.3160\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 109.8319 - mae: 7.7473 - val_loss: 1240.7504 - val_mae: 34.0666\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 67.7600 - mae: 6.1702 - val_loss: 1155.0208 - val_mae: 32.8029\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 76.8656 - mae: 6.6051 - val_loss: 1251.4830 - val_mae: 34.2632\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 71.0115 - mae: 6.5166 - val_loss: 1301.9650 - val_mae: 34.9979\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 60.3433 - mae: 5.4623 - val_loss: 1256.1803 - val_mae: 34.3366\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 108.0243 - mae: 7.7902 - val_loss: 1103.6080 - val_mae: 32.0242\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 96.1351 - mae: 7.6582 - val_loss: 1037.7455 - val_mae: 30.9578\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 63.5243 - mae: 6.1653 - val_loss: 1101.4774 - val_mae: 31.9581\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 92.6171 - mae: 7.0958 - val_loss: 1072.7030 - val_mae: 31.4977\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 76.4399 - mae: 6.5723 - val_loss: 1022.6839 - val_mae: 30.6890\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 80.1727 - mae: 6.6560 - val_loss: 907.7737 - val_mae: 28.7601\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 84.8881 - mae: 6.7360 - val_loss: 993.4699 - val_mae: 30.2337\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 64.0816 - mae: 5.4903 - val_loss: 1050.0353 - val_mae: 31.1658\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 75.7429 - mae: 6.7396 - val_loss: 1126.6766 - val_mae: 32.3779\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 89.2708 - mae: 6.8442 - val_loss: 1005.2920 - val_mae: 30.4305\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 75.3972 - mae: 6.4733 - val_loss: 968.3350 - val_mae: 29.7978\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 81.2424 - mae: 6.9464 - val_loss: 1146.1066 - val_mae: 32.6394\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 106.7760 - mae: 7.7025 - val_loss: 1036.3651 - val_mae: 30.8967\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 71.9518 - mae: 6.2091 - val_loss: 800.9104 - val_mae: 26.7931\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 108.0165 - mae: 7.7990 - val_loss: 1003.1183 - val_mae: 30.3364\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 67.4123 - mae: 6.2828 - val_loss: 1178.2789 - val_mae: 33.1130\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 143.4504 - mae: 9.0610 - val_loss: 998.3849 - val_mae: 30.2899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 80.2424 - mae: 6.4945 - val_loss: 770.5341 - val_mae: 26.2718\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 94.3352 - mae: 7.4182 - val_loss: 918.2161 - val_mae: 28.9638\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 75.6318 - mae: 6.4439 - val_loss: 1076.6376 - val_mae: 31.5871\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 97.7309 - mae: 6.9113 - val_loss: 937.4380 - val_mae: 29.2697\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 75.4175 - mae: 6.3888 - val_loss: 935.0950 - val_mae: 29.2215\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 74.4641 - mae: 6.6277 - val_loss: 971.1479 - val_mae: 29.8385\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 96.6483 - mae: 7.3654 - val_loss: 868.3317 - val_mae: 28.0551\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 64.9747 - mae: 5.9602 - val_loss: 769.9433 - val_mae: 26.2436\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 63.5245 - mae: 6.1055 - val_loss: 790.6574 - val_mae: 26.6322\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 76.5435 - mae: 6.4503 - val_loss: 985.3851 - val_mae: 30.0876\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 126.6118 - mae: 8.2031 - val_loss: 921.0449 - val_mae: 29.0022\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 68.9601 - mae: 6.0888 - val_loss: 686.7112 - val_mae: 24.5974\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 84.1650 - mae: 6.8074 - val_loss: 584.0972 - val_mae: 22.3601\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 125.9171 - mae: 8.2273 - val_loss: 811.8807 - val_mae: 27.0009\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 95.4958 - mae: 6.9429 - val_loss: 939.6332 - val_mae: 29.2892\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 72.3570 - mae: 6.7707 - val_loss: 741.2729 - val_mae: 25.6542\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 74.4325 - mae: 6.1518 - val_loss: 631.2966 - val_mae: 23.4075\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 81.2559 - mae: 7.0515 - val_loss: 653.7713 - val_mae: 23.8849\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 69.6375 - mae: 5.9593 - val_loss: 673.8980 - val_mae: 24.2672\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 76.0819 - mae: 6.6509 - val_loss: 739.2634 - val_mae: 25.5607\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 75.2478 - mae: 6.1137 - val_loss: 651.4024 - val_mae: 23.7418\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 77.7709 - mae: 6.4687 - val_loss: 541.6432 - val_mae: 21.2549\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 86.9274 - mae: 6.7179 - val_loss: 587.5159 - val_mae: 22.3047\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 66.5977 - mae: 6.1787 - val_loss: 681.7162 - val_mae: 24.3673\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 58.7609 - mae: 6.0279 - val_loss: 648.2288 - val_mae: 23.6826\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 109.7366 - mae: 7.1024 - val_loss: 541.3077 - val_mae: 21.3148\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 94.0551 - mae: 6.9869 - val_loss: 570.5651 - val_mae: 22.0179\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 109.6708 - mae: 8.0253 - val_loss: 772.9062 - val_mae: 26.2521\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 107.7510 - mae: 7.4320 - val_loss: 625.3213 - val_mae: 23.2344\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 72.0075 - mae: 6.5460 - val_loss: 462.4095 - val_mae: 19.6199\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 107.0102 - mae: 7.7173 - val_loss: 578.5298 - val_mae: 22.1050\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 71.1089 - mae: 6.3926 - val_loss: 777.2608 - val_mae: 26.1846\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 120.3955 - mae: 8.3282 - val_loss: 588.4953 - val_mae: 22.2270\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 93.6057 - mae: 6.8418 - val_loss: 413.0328 - val_mae: 18.4899\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 94.2986 - mae: 7.3616 - val_loss: 553.4444 - val_mae: 21.4613\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 109.1860 - mae: 7.1034 - val_loss: 617.3149 - val_mae: 22.7232\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 85.9681 - mae: 6.7012 - val_loss: 597.0759 - val_mae: 22.2386\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 85.6523 - mae: 6.7615 - val_loss: 531.9492 - val_mae: 20.9380\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 87.9791 - mae: 6.4768 - val_loss: 609.7762 - val_mae: 22.4922\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 94.5519 - mae: 6.9977 - val_loss: 611.9473 - val_mae: 22.5728\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 99.0554 - mae: 6.9387 - val_loss: 489.4572 - val_mae: 20.0226\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 81.3215 - mae: 6.6748 - val_loss: 513.4731 - val_mae: 20.5227\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 101.9142 - mae: 7.1539 - val_loss: 590.4072 - val_mae: 22.1311\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 71.0657 - mae: 5.8776 - val_loss: 520.1454 - val_mae: 20.6222\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 97.9123 - mae: 7.1542 - val_loss: 413.0311 - val_mae: 18.2526\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 67.4874 - mae: 6.4682 - val_loss: 457.3870 - val_mae: 19.2667\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 77.1647 - mae: 6.3681 - val_loss: 544.7576 - val_mae: 21.1043\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 85.2981 - mae: 6.9497 - val_loss: 438.6116 - val_mae: 18.9008\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 79.3946 - mae: 6.4099 - val_loss: 340.2832 - val_mae: 16.5346\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 88.4561 - mae: 6.9099 - val_loss: 408.9380 - val_mae: 18.3113\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 97.8388 - mae: 7.1697 - val_loss: 627.9908 - val_mae: 23.1904\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 100.8469 - mae: 7.6496 - val_loss: 491.1649 - val_mae: 20.2094\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 78.0671 - mae: 6.4289 - val_loss: 308.5898 - val_mae: 15.8603\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 87.3776 - mae: 7.1988 - val_loss: 442.8311 - val_mae: 19.2117\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 128.3494 - mae: 7.9334 - val_loss: 588.2679 - val_mae: 22.2675\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 110.5782 - mae: 7.4674 - val_loss: 445.8651 - val_mae: 19.2985\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 65.3828 - mae: 6.0103 - val_loss: 314.7159 - val_mae: 15.9993\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 65.8705 - mae: 6.1270 - val_loss: 302.5499 - val_mae: 15.6185\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 75.7686 - mae: 6.2363 - val_loss: 346.3142 - val_mae: 16.7958\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 80.1578 - mae: 7.0223 - val_loss: 395.2420 - val_mae: 18.0043\n",
      "Epoch 359/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 53ms/step - loss: 69.6517 - mae: 6.1945 - val_loss: 268.7124 - val_mae: 14.4740\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 79.8276 - mae: 6.6463 - val_loss: 287.1634 - val_mae: 15.0484\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 72.5132 - mae: 6.1256 - val_loss: 379.2899 - val_mae: 17.5600\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 77.8938 - mae: 6.4137 - val_loss: 421.2457 - val_mae: 18.5678\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 84.5184 - mae: 6.9004 - val_loss: 278.6893 - val_mae: 14.7441\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 111.6572 - mae: 7.7136 - val_loss: 276.3309 - val_mae: 14.6569\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 84.2046 - mae: 6.7863 - val_loss: 401.0660 - val_mae: 18.0885\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 65.8059 - mae: 6.1372 - val_loss: 374.0708 - val_mae: 17.4722\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 83.2731 - mae: 6.9620 - val_loss: 357.7409 - val_mae: 17.0872\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 91.2554 - mae: 6.8271 - val_loss: 287.3831 - val_mae: 15.1483\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 90.6982 - mae: 7.3585 - val_loss: 288.4576 - val_mae: 15.1548\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 75.6973 - mae: 6.1845 - val_loss: 267.6364 - val_mae: 14.4804\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 66.0258 - mae: 6.2821 - val_loss: 288.3963 - val_mae: 15.1118\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 79.8578 - mae: 6.5117 - val_loss: 306.9010 - val_mae: 15.6497\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 62.2701 - mae: 5.4810 - val_loss: 288.1837 - val_mae: 15.0699\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 103.3981 - mae: 7.1649 - val_loss: 264.3673 - val_mae: 14.2849\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 82.7671 - mae: 6.4315 - val_loss: 259.9906 - val_mae: 14.1356\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 93.4513 - mae: 6.5000 - val_loss: 255.7191 - val_mae: 13.9905\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 70.9199 - mae: 6.5671 - val_loss: 245.1639 - val_mae: 13.6230\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 79.8282 - mae: 6.3648 - val_loss: 277.8745 - val_mae: 14.7098\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 78.3722 - mae: 6.7375 - val_loss: 310.3227 - val_mae: 15.6859\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 93.5675 - mae: 6.7492 - val_loss: 330.9319 - val_mae: 16.2604\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 83.4297 - mae: 6.7310 - val_loss: 268.0146 - val_mae: 14.3547\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 76.0050 - mae: 6.5618 - val_loss: 251.0241 - val_mae: 13.7507\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 87.2052 - mae: 7.0366 - val_loss: 309.5420 - val_mae: 15.6125\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 110.9088 - mae: 7.5668 - val_loss: 277.2103 - val_mae: 14.5232\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 86.0086 - mae: 6.7532 - val_loss: 293.6223 - val_mae: 15.0345\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 60.2073 - mae: 5.7456 - val_loss: 228.3868 - val_mae: 12.6608\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 81.1282 - mae: 6.6892 - val_loss: 253.7383 - val_mae: 13.5950\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 91.3979 - mae: 6.7165 - val_loss: 469.5448 - val_mae: 19.5805\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 101.9862 - mae: 7.8535 - val_loss: 324.2093 - val_mae: 15.9590\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 104.0117 - mae: 7.4981 - val_loss: 159.0447 - val_mae: 9.9592\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 82.1674 - mae: 7.5105 - val_loss: 169.6024 - val_mae: 10.3431\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 68.9621 - mae: 6.0914 - val_loss: 356.5074 - val_mae: 16.7547\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 105.6162 - mae: 7.5666 - val_loss: 338.6597 - val_mae: 16.2190\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 91.2933 - mae: 7.2421 - val_loss: 230.0433 - val_mae: 12.4815\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 86.1097 - mae: 6.8446 - val_loss: 177.1428 - val_mae: 10.7293\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 108.2324 - mae: 7.7043 - val_loss: 255.5367 - val_mae: 13.3948\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 71.1514 - mae: 6.0142 - val_loss: 344.0753 - val_mae: 16.3020\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 95.2377 - mae: 7.0845 - val_loss: 254.1285 - val_mae: 13.3675\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 103.8480 - mae: 7.1367 - val_loss: 181.0242 - val_mae: 10.8244\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 54.2269 - mae: 5.4633 - val_loss: 226.3265 - val_mae: 12.2693\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 75.7304 - mae: 6.5061 - val_loss: 295.1652 - val_mae: 14.8965\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 76.3270 - mae: 6.2353 - val_loss: 284.3268 - val_mae: 14.6405\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 140.5337 - mae: 9.0008 - val_loss: 177.5141 - val_mae: 10.7818\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 67.3249 - mae: 6.1632 - val_loss: 159.9392 - val_mae: 9.9837\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 91.0794 - mae: 6.9037 - val_loss: 300.3876 - val_mae: 15.2358\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 112.0112 - mae: 8.1854 - val_loss: 304.5719 - val_mae: 15.3864\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 108.2473 - mae: 7.8389 - val_loss: 167.0116 - val_mae: 10.2527\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 87.9799 - mae: 7.0908 - val_loss: 154.6239 - val_mae: 9.7107\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 98.9688 - mae: 7.6549 - val_loss: 271.1453 - val_mae: 14.2621\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 66.0248 - mae: 6.0353 - val_loss: 376.2332 - val_mae: 17.3954\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 110.3618 - mae: 8.1449 - val_loss: 245.6215 - val_mae: 13.3641\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 72.0114 - mae: 6.1476 - val_loss: 155.5642 - val_mae: 10.0117\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 77.3049 - mae: 6.3510 - val_loss: 217.8765 - val_mae: 12.3465\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 60.2498 - mae: 5.6692 - val_loss: 262.2327 - val_mae: 14.0655\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 63.2532 - mae: 6.0267 - val_loss: 237.1869 - val_mae: 13.1669\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 68.8496 - mae: 6.2294 - val_loss: 186.5103 - val_mae: 11.0369\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 77.5410 - mae: 6.2401 - val_loss: 195.1762 - val_mae: 11.2655\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 73.2074 - mae: 6.3636 - val_loss: 253.1358 - val_mae: 13.5577\n",
      "Epoch 419/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 49ms/step - loss: 83.6256 - mae: 6.8300 - val_loss: 191.5955 - val_mae: 11.1086\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 85.0022 - mae: 6.5388 - val_loss: 159.0439 - val_mae: 9.9606\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 90.9139 - mae: 7.0719 - val_loss: 183.2424 - val_mae: 10.7946\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 92.1742 - mae: 7.0257 - val_loss: 281.0243 - val_mae: 14.6704\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 99.3484 - mae: 7.5848 - val_loss: 239.5832 - val_mae: 13.2136\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 112.9667 - mae: 6.9656 - val_loss: 158.8138 - val_mae: 9.9687\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 78.8411 - mae: 6.6873 - val_loss: 154.2377 - val_mae: 9.7941\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 109.9094 - mae: 7.4838 - val_loss: 224.1524 - val_mae: 12.3959\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 72.4712 - mae: 6.0960 - val_loss: 244.0563 - val_mae: 13.1044\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 84.0819 - mae: 6.4700 - val_loss: 175.3641 - val_mae: 10.8289\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 66.2338 - mae: 6.2860 - val_loss: 150.0384 - val_mae: 9.4849\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 73.2503 - mae: 6.3310 - val_loss: 193.3330 - val_mae: 11.3722\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 79.2058 - mae: 6.7748 - val_loss: 279.1003 - val_mae: 14.0260\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 95.3505 - mae: 7.0969 - val_loss: 203.2633 - val_mae: 11.7176\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 67.4124 - mae: 5.6488 - val_loss: 181.8051 - val_mae: 10.9180\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 91.3578 - mae: 7.1909 - val_loss: 275.1182 - val_mae: 14.0038\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 97.7840 - mae: 7.3336 - val_loss: 283.0180 - val_mae: 14.3969\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 60.6715 - mae: 5.6189 - val_loss: 201.7650 - val_mae: 11.8424\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 93.2579 - mae: 7.0175 - val_loss: 174.6109 - val_mae: 10.8650\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 89.4596 - mae: 7.2506 - val_loss: 211.4232 - val_mae: 12.0770\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 61.6225 - mae: 5.6324 - val_loss: 205.3290 - val_mae: 11.8694\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 107.9000 - mae: 7.2574 - val_loss: 152.2502 - val_mae: 9.8193\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 77.2870 - mae: 6.5218 - val_loss: 165.3567 - val_mae: 10.4338\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 72.2755 - mae: 6.3963 - val_loss: 212.4916 - val_mae: 12.1254\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 80.8536 - mae: 6.5966 - val_loss: 170.8353 - val_mae: 10.6088\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 57.2291 - mae: 5.4665 - val_loss: 152.7262 - val_mae: 9.8703\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 100.2112 - mae: 7.0396 - val_loss: 168.8171 - val_mae: 10.5238\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 74.9064 - mae: 5.9858 - val_loss: 166.1710 - val_mae: 10.3990\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 83.4558 - mae: 6.8040 - val_loss: 189.3641 - val_mae: 11.2113\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 103.1603 - mae: 7.0046 - val_loss: 205.8658 - val_mae: 11.7322\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 69.2201 - mae: 5.5785 - val_loss: 187.6456 - val_mae: 11.2215\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 52.5422 - mae: 5.4273 - val_loss: 199.2654 - val_mae: 11.6437\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 58.6540 - mae: 5.4402 - val_loss: 176.6734 - val_mae: 10.8014\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 98.2858 - mae: 7.0221 - val_loss: 185.0784 - val_mae: 11.1036\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 104.9502 - mae: 7.3559 - val_loss: 185.2778 - val_mae: 11.0418\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 88.3616 - mae: 6.6429 - val_loss: 197.2239 - val_mae: 11.4405\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 55.0568 - mae: 5.4139 - val_loss: 186.2342 - val_mae: 11.0170\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 91.1809 - mae: 6.5592 - val_loss: 156.4048 - val_mae: 9.8082\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 70.0254 - mae: 6.0077 - val_loss: 164.6815 - val_mae: 10.2063\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 71.0188 - mae: 6.1316 - val_loss: 171.9739 - val_mae: 10.4054\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 64.5160 - mae: 5.8391 - val_loss: 219.2365 - val_mae: 11.9456\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 91.3178 - mae: 6.9756 - val_loss: 176.0709 - val_mae: 10.5502\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 105.2686 - mae: 6.8179 - val_loss: 175.1909 - val_mae: 10.5432\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 99.0010 - mae: 7.1427 - val_loss: 207.5742 - val_mae: 11.6116\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 74.0400 - mae: 5.9432 - val_loss: 157.7019 - val_mae: 9.8179\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 84.8863 - mae: 6.7701 - val_loss: 145.4040 - val_mae: 9.5705\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 105.9233 - mae: 7.7047 - val_loss: 178.6307 - val_mae: 10.6541\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 106.2924 - mae: 8.1132 - val_loss: 245.3609 - val_mae: 12.9859\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 78.5319 - mae: 7.1430 - val_loss: 159.9017 - val_mae: 9.8133\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 84.8247 - mae: 6.6982 - val_loss: 144.9975 - val_mae: 9.7473\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 121.0001 - mae: 7.9521 - val_loss: 175.1218 - val_mae: 10.4281\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 87.8481 - mae: 6.9486 - val_loss: 349.0135 - val_mae: 16.5534\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 96.4554 - mae: 8.1391 - val_loss: 261.5365 - val_mae: 13.8189\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 100.2919 - mae: 7.2452 - val_loss: 139.1284 - val_mae: 8.8895\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 73.5477 - mae: 6.9722 - val_loss: 133.0112 - val_mae: 9.0323\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 92.3828 - mae: 7.5478 - val_loss: 190.0706 - val_mae: 11.0843\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 82.6611 - mae: 6.3099 - val_loss: 265.1891 - val_mae: 13.7886\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 80.3932 - mae: 6.6444 - val_loss: 212.0342 - val_mae: 11.8211\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 80.4951 - mae: 6.3591 - val_loss: 142.6999 - val_mae: 9.2869\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 94.8749 - mae: 6.9588 - val_loss: 145.2468 - val_mae: 9.2392\n",
      "Epoch 479/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 57ms/step - loss: 45.8736 - mae: 5.0153 - val_loss: 238.7526 - val_mae: 12.9528\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 91.5437 - mae: 7.4809 - val_loss: 192.6549 - val_mae: 11.3459\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 67.4306 - mae: 6.3327 - val_loss: 135.0803 - val_mae: 8.8868\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 115.4985 - mae: 7.9267 - val_loss: 188.2481 - val_mae: 11.1421\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 83.7398 - mae: 6.5713 - val_loss: 250.3968 - val_mae: 13.3055\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 83.8834 - mae: 6.6834 - val_loss: 198.7735 - val_mae: 11.3937\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 67.3887 - mae: 5.8179 - val_loss: 168.4280 - val_mae: 10.4261\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 59.6723 - mae: 5.6436 - val_loss: 165.7551 - val_mae: 10.3650\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 81.5223 - mae: 6.6578 - val_loss: 176.0530 - val_mae: 10.7826\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 88.3353 - mae: 6.9554 - val_loss: 172.8046 - val_mae: 10.6485\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 63.8116 - mae: 5.7282 - val_loss: 165.2280 - val_mae: 10.2828\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 81.6245 - mae: 6.0818 - val_loss: 189.0939 - val_mae: 11.0894\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 111.8216 - mae: 7.6590 - val_loss: 193.9439 - val_mae: 11.1354\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 86.0194 - mae: 6.6338 - val_loss: 202.1003 - val_mae: 11.3551\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 58.6087 - mae: 5.9084 - val_loss: 210.9773 - val_mae: 11.6042\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 61.9626 - mae: 5.6913 - val_loss: 208.4016 - val_mae: 11.5190\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 80.6549 - mae: 6.3228 - val_loss: 181.5478 - val_mae: 10.8085\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 88.5659 - mae: 7.0574 - val_loss: 177.2285 - val_mae: 10.8142\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 75.2436 - mae: 6.1757 - val_loss: 189.3430 - val_mae: 11.0967\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 100.1589 - mae: 6.9052 - val_loss: 196.9412 - val_mae: 11.2731\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 85.7592 - mae: 6.7327 - val_loss: 171.9841 - val_mae: 10.4402\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 73.9014 - mae: 6.0629 - val_loss: 181.6195 - val_mae: 10.8088\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data, Y, epochs=500, validation_split=0.1, batch_size=64, callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.reshape(test_data.shape[0],90,90,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24.668821]\n",
      " [19.086489]\n",
      " [18.351332]\n",
      " [20.43825 ]\n",
      " [22.717564]\n",
      " [23.613379]\n",
      " [44.321823]\n",
      " [39.27758 ]\n",
      " [45.609646]\n",
      " [59.143345]\n",
      " [65.64745 ]\n",
      " [66.76102 ]\n",
      " [72.38603 ]\n",
      " [66.36529 ]\n",
      " [15.914827]\n",
      " [18.5743  ]\n",
      " [16.242485]\n",
      " [33.26451 ]\n",
      " [22.74307 ]\n",
      " [27.73098 ]\n",
      " [46.97158 ]\n",
      " [58.94708 ]\n",
      " [50.658524]\n",
      " [67.75148 ]\n",
      " [48.500248]\n",
      " [53.125446]\n",
      " [54.314137]\n",
      " [57.50042 ]]\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(test_data)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'example_submission.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [94]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[0;32m      3\u001b[0m header \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexample_submission.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUTF8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      6\u001b[0m     writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(f)\n\u001b[0;32m      8\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriterow(header)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'example_submission.csv'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "header = ['id', 'age']\n",
    "\n",
    "with open('example_submission.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    i=0\n",
    "    for p in pred:\n",
    "        writer.writerow([i+1, pred[i][0]])\n",
    "        i = i+1\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
